{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2020-03-24_colab_vgg-cnn network.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":["xsMY2VZgywF8"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"p45UjNjFyoHc","colab_type":"text"},"source":["# VGG type convolutional neural network (CNN) classifier"]},{"cell_type":"markdown","metadata":{"id":"xsMY2VZgywF8","colab_type":"text"},"source":["## Notes\n","\n","* **Reference** : Simonyan, K. and Zisserman, A. (2015) '*Very Deep Convolutional Networks for Large-Scale Image Recognition*'. arXiv:1409.1556.\n"]},{"cell_type":"markdown","metadata":{"id":"HF4Lk4ZVe0Nj","colab_type":"text"},"source":["## Create a VGG type convolutional neural network (CNN) classifier in Keras"]},{"cell_type":"markdown","metadata":{"id":"0mIcpL6pLPvL","colab_type":"text"},"source":["### Import required Python libraries\n","\n"]},{"cell_type":"code","metadata":{"id":"jaV4mHBXVj2x","colab_type":"code","colab":{}},"source":["import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Activation\n","from tensorflow.python.keras.layers import Conv2D, MaxPooling2D\n","from tensorflow.keras.layers import Dense, Dropout, Flatten\n","from tensorflow.keras.optimizers import SGD"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BVMwTVUOV1KY","colab_type":"text"},"source":["### Import and shape the dataset\n","\n","* typically the data should be pre-processed and shaped before being imported\n","* typically the dataset, comprising a set of **input:ouput pairs**, is split in a **seen** dataset used for *training* and *validating* the neural network, and an **unseen** dataset used for *testing* the performance of the trained neural network with: <br>\n","sklearn.model_selection.train_test_split\n","* the output class of each sample needs to be **one-hot encoded** for classification applications"]},{"cell_type":"code","metadata":{"id":"lxMLelekV8xh","colab_type":"code","colab":{}},"source":["print('* Importing and shaping the data *')\n","print()\n","\n","mnist = tf.keras.datasets.mnist  # load mnist dataset from tensorflow\n","(input_train, output_train_class), (input_test, output_test_class) = mnist.load_data()\n","\n","print('input_train (original): ', input_train.shape)\n","print('input_test (original): ', input_test.shape)\n","print()\n","\n","input_train= input_train.reshape(input_train.shape[0], 28, 28, 1)  # add an extra dimension to array\n","input_test= input_test.reshape(input_test.shape[0], 28, 28, 1)\n","\n","input_train = input_train / 255.0  # max normalise the image data[0:1]\n","input_test = input_test / 255.0\n","\n","output_train_class_onehot = tf.keras.utils.to_categorical(output_train_class, 10)  # create one-hot encoded class\n","output_test_class_onehot = tf.keras.utils.to_categorical(output_test_class, 10)\n","\n","output_class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']    # class names string\n","\n","print('input_train : ', input_train.shape)\n","print('output_train_class : ', output_train_class.shape)\n","print('output_train_class_onehot : ', output_train_class_onehot.shape)\n","print()\n","print('input_test : ', input_test.shape)\n","print('output_test_class : ', output_test_class.shape)\n","print('output_test_class_onehot : ', output_test_class_onehot.shape)\n","print()\n","print('output_class_names : ', output_class_names)\n","print()\n","\n","item_id = 5\n","\n","print('item_id : ', item_id)\n","print('output_train_class [item_id] : ', output_train_class[item_id])\n","print('output_train_class_onehot [item_id] : ', output_train_class_onehot[item_id, :])\n","\n","plt.imshow(input_train[item_id, :, :, 0], cmap=plt.cm.binary)\n","plt.title('input_train [' + str(item_id) + ']')\n","plt.grid(None)\n","plt.xticks([])\n","plt.yticks([])\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kgB--wW0dGPU","colab_type":"text"},"source":["### Define the network hyperparameters\n","\n","* **hyperparameters** are the variables which determine the network structure and how the network is trained\n","* structural hyperparameters: number of hidden layers, number of nodes in each layer...\n","* training hyperparameters: learning rate, dropout ratio, number of epochs...\n","* hyperparameters are set before training"]},{"cell_type":"code","metadata":{"id":"GdlhlPRPdZck","colab_type":"code","colab":{}},"source":["optimizer_type = SGD(lr=0.2)  # optimisation algorithm: SGD stochastic gradient decent \n","loss = 'categorical_crossentropy'  # loss (cost) function to be minimised by the optimiser\n","metrics = ['categorical_accuracy']  # network accuracy metric to be determined after each epoch\n","dropout_ratio = 0.0  # % of nodes in the hidden layer to dropout during back-propagation update of the network weights\n","validtrain_split_ratio = 0.2  # % of the seen dataset to be put aside for validation, rest is for training\n","max_epochs = 40  # maxmimum number of epochs to be iterated\n","batch_size = 500   # batch size for the training data set\n","batch_shuffle = True   # shuffle the training data prior to batching before each epoch\n","num_hidden_nodes = 256  # number of nodes in hidden fully connected layer"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y6JHphuLcvb6","colab_type":"text"},"source":["### Define the network architecture\n","\n","* using the Keras' *functional* model  [[Link]](https://keras.io/models/model/)\n","* can also use Keras' *sequential* model but limited to simpler architectures  [[Link]](https://keras.io/models/sequential/)\n","* can specify the type of each layer, for example dense (fully connected), convolutional, dropout etc. [[Link]](https://keras.io/layers/about-keras-layers/)\n","* can specify the activation function to be used in each layer, for example sigmoid, relu etc. [[Link]](https://keras.io/activations/)\n","* **softmax** activation, also known as *softargmax* or *normalized exponential function*, is typically used for the final layer of a classifier network to normalise its output into a probability distribution of the classes\n","* network weights are typically initialised with random values\n"]},{"cell_type":"code","metadata":{"id":"TVOQwMTkdrdb","colab_type":"code","colab":{}},"source":["input_shape = (28, 28, 1)\n","inputs = Input(shape=input_shape)\n","\n","down_01 = Conv2D(filters=16, kernel_size=(3, 3), strides=(1, 1), padding='same')(inputs)\n","down_01 = Activation('relu')(down_01)\n","down_01 = Conv2D(filters=16, kernel_size=(3, 3), strides=(1, 1), padding='same')(down_01)\n","down_01 = Activation('relu')(down_01)\n","\n","down_01_pool = MaxPooling2D((2, 2), strides=(2, 2))(down_01)   # maxpool downsampled to 14x14x16\n","\n","down_02 = Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), padding='same')(down_01_pool)\n","down_02 = Activation('relu')(down_02)\n","down_02 = Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), padding='same')(down_02)\n","down_02 = Activation('relu')(down_02)\n","\n","down_02_pool = MaxPooling2D((2, 2), strides=(2, 2))(down_02)   # maxpool downsampled to 7x7x32\n","\n","flatten = Flatten()(down_02_pool)   # 1568 nodes\n","\n","dense_01 = Dense(num_hidden_nodes)(flatten)\n","dense_01 = Activation('sigmoid')(dense_01)\n","dense_01 = Dropout(dropout_ratio)(dense_01)\n","\n","dense_02 = Dense(10)(dense_01)\n","outputs = Activation('softmax')(dense_02)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DwllZ6zVd9QM","colab_type":"text"},"source":["### Compile the network\n","\n","* compile the defined network architecture with the stated **optimizer algorithm** [[Link]](https://keras.io/optimizers/), **loss (cost) function**  [[Link]](https://keras.io/losses/), and **accuracy metrics** [[Link]](https://keras.io/metrics/) using: .compile()\n","* print network architecture using: .summary()\n","* create and save a schematic image of the network architecture using: .plot_model()\n","* schematic image saved to the runtime disk, remember to download to local machine before termination"]},{"cell_type":"code","metadata":{"id":"8ngMDyUFeCDL","colab_type":"code","colab":{}},"source":["print()\n","print('* Compiling the network model *')\n","print()\n","\n","model = Model(inputs=inputs, outputs=outputs)\n","model.compile(optimizer=optimizer_type, loss=loss, metrics=metrics)\n","\n","# display a summary of the compiled neural network\n","\n","print(model.summary())  \n","print()\n","\n","# create and save a schematic image of the network architecture\n","\n","from tensorflow.keras.utils import plot_model\n","from IPython.display import Image\n","\n","print('Graphical schematic of the compiled network')\n","print()\n","\n","plot_model(model, show_shapes=True, show_layer_names=True, to_file='model.png')\n","Image(filename='model.png')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TvfyQk9LgaEz","colab_type":"text"},"source":["### Train the neural network with the training dataset\n","\n","* the **seen** dataset is split into **training** and **validation** subsets\n","* the training set can be broken down into **batches**\n","* the network weights are updated after each training batch by back propagation using the **optimiser** algorithm to minimise the **loss (cost) function**\n","* one **epoch** is one training cycle of all training batches\n","* after all training batches have been processed in an epoch, the network is tested with the validation data set and the resulting loss function and accuracy metrics are displayed\n","* the training data can be shuffled and rebatched before each epoch\n","* training continues until the stated maximum number of epochs has been reached or an early stop criteria has been satisfied, for example when the loss (cost) function begins to increase"]},{"cell_type":"code","metadata":{"id":"qmXxAsVZggoD","colab_type":"code","colab":{}},"source":["print('* Training the compiled network *')\n","print()\n","\n","history = model.fit(input_train, output_train_class_onehot, \\\n","                    batch_size=batch_size, \\\n","                    epochs=max_epochs, \\\n","                    validation_split=validtrain_split_ratio, \\\n","                    shuffle=batch_shuffle)\n","\n","print()\n","print('Training completed')\n","print()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fT1FYewGwOo6","colab_type":"text"},"source":["### Plot the training history of the network\n","\n","* usefull for seeing the convergence of the training, oscillations of the cost function between local minima, and the presence of over fitting"]},{"cell_type":"code","metadata":{"id":"_3NEJ2AywWZh","colab_type":"code","colab":{}},"source":["# model loss\n","\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Model loss : ' + loss)\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['Training', 'Validation'], loc='best')\n","plt.show()\n","plt.close()\n","\n","# model accuracy metric\n","\n","plt.plot(np.array(history.history[metrics[0]]))\n","plt.plot(np.array(history.history['val_' + metrics[0]]))\n","plt.title('Model accuracy metric : ' + metrics[0])\n","plt.ylabel('Accuracy metric')\n","plt.xlabel('Epoch')\n","plt.legend(['Training', 'Validation'], loc='best')\n","plt.show()\n","plt.close()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FgUczSigiDFl","colab_type":"text"},"source":["### Evaluate the trained network performance on the unseen test dataset\n","\n","* the performance of the trained network on unseen test data can be assessed using: .evaluate()"]},{"cell_type":"code","metadata":{"id":"fKV_mSM76IK2","colab_type":"code","colab":{}},"source":["print('* Evaluating the performance of the trained network on the unseen test dataset *')\n","print()\n","\n","evaluate_model = model.evaluate(x=input_test, y=output_test_class_onehot)\n","loss_metric = evaluate_model [0]\n","accuracy_metric = evaluate_model [1]\n","\n","print()\n","print('Accuracy - ' + metrics[0] + ': %0.3f'%accuracy_metric)\n","print('Loss - ' + loss + ': %0.3f'%loss_metric)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jeMbVYzT1j48","colab_type":"text"},"source":["### Create and display the test set classification report\n","\n","* provides in-depth statistics of the test data predictions provided by the trained neural network"]},{"cell_type":"code","metadata":{"id":"RkIlN6T_1uXM","colab_type":"code","colab":{}},"source":["from sklearn.metrics import classification_report\n","\n","output_predict_class_onehot = model.predict(input_test)\n","output_predict_class = np.argmax(output_predict_class_onehot, axis=1)\n","\n","print('* Test set classification report *')\n","print()\n","print(classification_report(output_test_class, output_predict_class,  \\\n","                            target_names=output_class_names))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NrWdaKZF3-3a","colab_type":"text"},"source":["### Display the test set confusion probability matrix\n","\n",". usefull way of seeing which classes the trained network mixes up"]},{"cell_type":"code","metadata":{"id":"O4niQpLj4EL5","colab_type":"code","colab":{}},"source":["print('* Confusion probability matrix *')\n","print()\n","\n","import itertools\n","\n","from sklearn.metrics import confusion_matrix\n","\n","\n","confusion_matrix = confusion_matrix(output_test_class, output_predict_class)  # confusion matrix\n","\n","confusion_probability_matrix = confusion_matrix.astype('float') / \\\n","                               confusion_matrix.sum(axis=1)[:, np.newaxis]  # row normalisation of confusion matrix\n","confusion_probability_matrix = confusion_probability_matrix * 100.0  # confusion probability matrix\n","\n","plt.imshow(confusion_probability_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n","plt.title('Normalised confusion matrix')    \n","plt.colorbar(label='%')\n","plt.clim(0, 100)\n","tick_marks = np.arange(len(output_class_names))\n","plt.xticks(tick_marks, output_class_names, rotation=0)\n","plt.yticks(tick_marks, output_class_names)\n","fmt = '.1f'\n","thresh = confusion_probability_matrix.max() / 2.0\n","for i, j in itertools.product(range(confusion_probability_matrix.shape[0]), range(confusion_probability_matrix.shape[1])):\n","    plt.text(j, i, format(confusion_probability_matrix[i, j], fmt),\n","             horizontalalignment='center',\n","             color='white' if confusion_probability_matrix[i, j] > thresh else 'black')    \n","plt.tight_layout()\n","plt.ylabel('True label')\n","plt.xlabel('Predicted label')\n","plt.grid(None)\n","plt.show()\n","plt.close()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xI_9EivUxeko","colab_type":"text"},"source":["### Predict the class of a given input\n","\n","* might need to reshape the input to match the network input shape\n","* need to apply an *argmax* to the estimated probabilty distribution provided by the trained network to define the predicted class"]},{"cell_type":"code","metadata":{"id":"D9Fa0l6KNV1A","colab_type":"code","colab":{}},"source":["print('* Predicting the class of a given input *')\n","print()\n","\n","test_id = 58\n","\n","input_predict = np.zeros(shape=(1, 28, 28, 1))  # create numpy array of required dimensions for network input\n","\n","input_predict[0, :, :, 0] = input_test[test_id, :, :, 0]  # reshaping test input image\n","\n","output_predict_class_onehot = model.predict(input_predict)  # softmax distribution of predicted class\n","\n","output_predict_class = np.argmax(output_predict_class_onehot[0])  # predicted class of input\n","\n","print('test_id : ', test_id)\n","print()\n","print('output_predict_class_onehot [test_id]: \\n\\n', output_predict_class_onehot)\n","print()\n","print('sum[output_predict_class_onehot [test_id]] : ', np.sum(output_predict_class_onehot))  # should be = 1.0\n","print()\n","print('output_test_class_onehot [item_id] : ', output_test_class_onehot[test_id])\n","print()\n","print('output_test_class [item_id] : ', output_test_class[test_id])\n","print()\n","print('output_predict_class [item_id] : ', output_predict_class)\n","print()\n","\n","plt.imshow(input_test[test_id, :, :, 0], cmap=plt.cm.binary)\n","plt.title('input_test [' + str(test_id) + ']')\n","plt.grid(None)\n","plt.xticks([])\n","plt.yticks([])\n","plt.show()\n"],"execution_count":0,"outputs":[]}]}