{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2020-03-31_U-net.ipynb","provenance":[{"file_id":"1VT69LY6bT_LZlT9sMGWGwUBK4-K86fxh","timestamp":1554763498797},{"file_id":"11aj9JnEOFImLL4fC2sV5tBBJi7iYDKiG","timestamp":1554761981152},{"file_id":"1LsfPFefoBmdYT8HqRE38itBr46o3Aey2","timestamp":1554758510525},{"file_id":"1MszsYWxYQb3pdJg88PN49hkuwwIt2VaL","timestamp":1554755251350}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"v74B0Tnlfe4c","colab_type":"text"},"source":["# U-net Task 1"]},{"cell_type":"markdown","metadata":{"id":"4MiKScJgfp3q","colab_type":"text"},"source":["## import libraries"]},{"cell_type":"code","metadata":{"id":"jPLikxt7frWt","colab_type":"code","colab":{}},"source":["import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import glob\n","import cv2\n","\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Activation\n","from tensorflow.python.keras.layers import Conv2D, MaxPooling2D, LeakyReLU\n","from tensorflow.python.keras.layers import concatenate, UpSampling2D, BatchNormalization\n","from tensorflow.keras.optimizers import Adam"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zgrmq6KufwC4","colab_type":"text"},"source":["## Dowload images"]},{"cell_type":"code","metadata":{"id":"SUJKMhsrfrzU","colab_type":"code","colab":{}},"source":["!pip install wget\n","import wget\n","import os\n","url = \"https://people.eecs.berkeley.edu/~tinghuiz/projects/pix2pix/datasets/facades.tar.gz\"\n","wget.download(url, '.')\n","!tar -zxvf facades.tar.gz"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AB5T7ENrq7d9","colab_type":"code","colab":{}},"source":["# import and normalize train, test, and validation images\n","files_train = glob.glob('facades/train/*')\n","pass_train = [i for i in files_train]\n","input_train = np.array([cv2.cvtColor(cv2.imread(i, cv2.IMREAD_COLOR)[:,256:,:], cv2.COLOR_BGR2RGB) for i in pass_train])\n","output_train = np.array([cv2.cvtColor(cv2.imread(i, cv2.IMREAD_COLOR)[:,:256,:], cv2.COLOR_BGR2RGB) for i in pass_train])\n","input_train = input_train/255.0\n","output_train = output_train/255.0\n","# input_train = 2.0*input_train/255.0 - 1.0\n","# output_train = 2.0*output_train/255.0 - 1.0\n","\n","files_test = glob.glob('facades/test/*')\n","pass_test = [i for i in files_test]\n","input_test = np.array([cv2.cvtColor(cv2.imread(i, cv2.IMREAD_COLOR)[:,256:,:], cv2.COLOR_BGR2RGB) for i in pass_test])\n","output_test = np.array([cv2.cvtColor(cv2.imread(i, cv2.IMREAD_COLOR)[:,:256,:], cv2.COLOR_BGR2RGB) for i in pass_test])\n","input_test = input_test/255.0 \n","output_test = output_test/255.0\n","# input_test = 2.0*input_test/255.0 - 1.0\n","# output_test = 2.0*output_test/255.0 - 1.0\n","\n","files_val = glob.glob('facades/val/*')\n","pass_val = [i for i in files_val]\n","input_val = np.array([cv2.cvtColor(cv2.imread(i, cv2.IMREAD_COLOR)[:,256:,:], cv2.COLOR_BGR2RGB) for i in pass_val])\n","output_val = np.array([cv2.cvtColor(cv2.imread(i, cv2.IMREAD_COLOR)[:,:256,:], cv2.COLOR_BGR2RGB) for i in pass_val])\n","input_val = input_val/255.0\n","output_val = output_val/255.0\n","# input_val = 2.0*input_val/255.0 - 1.0\n","# output_val = 2.0*output_val/255.0 - 1.0\n","\n","print('input_train : ', input_train.shape)\n","print('output_train : ', output_train.shape)\n","print('input_val : ', input_val.shape)\n","print('output_val : ', output_val.shape)\n","print('input_test : ', input_test.shape)\n","print('output_test : ', output_test.shape)\n","print()\n","print('Plot example from training set')\n","print()\n","item_id = 5\n","print('item_id : ', item_id)\n","print()\n","\n","# show sample training input and output\n","plt.imshow((input_train[item_id]+0.0 ) / 1.0)\n","plt.title('input_train [' + str(item_id) + ']')\n","plt.grid(None)\n","plt.xticks([])\n","plt.yticks([])\n","plt.show()\n","\n","plt.imshow((output_train[item_id]+0.0 ) / 1.0)\n","plt.title('output_train [' + str(item_id) + ']')\n","plt.grid(None)\n","plt.xticks([])\n","plt.yticks([])\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y_3CvcyntxqN","colab_type":"text"},"source":["## Define network"]},{"cell_type":"code","metadata":{"id":"p2L5JD8lr27Z","colab_type":"code","colab":{}},"source":["def unet(\n","    input_train = input_train, \n","    output_train = output_train,\n","    input_val = input_val,\n","    output_val = output_val,\n","    optimizer_type = Adam(lr=2e-4),\n","    loss = 'mean_squared_error',\n","    dropout_ratio = 0.0,\n","    max_epochs = 50,\n","    batch_size = 32,\n","    batch_shuffle = True,\n","    remove_skipconnection = False):\n","\n","    # define input shape\n","    input_shape = (256, 256, 3)\n","    inputs = Input(shape=input_shape)\n","\n","    # encoder section\n","\n","    down0 = Conv2D(64, (4, 4), strides=(2, 2), padding='same')(inputs)\n","    down0 = BatchNormalization()(down0)\n","    down0 = LeakyReLU()(down0)\n","\n","    down1 = Conv2D(128, (4, 4), strides=(2, 2), padding='same')(down0)\n","    down1 = BatchNormalization()(down1)\n","    down1 = LeakyReLU()(down1)\n","\n","    down2 = Conv2D(256, (4, 4), strides=(2, 2), padding='same')(down1)\n","    down2 = BatchNormalization()(down2)\n","    down2 = LeakyReLU()(down2)\n","\n","    down3 = Conv2D(512, (4, 4), strides=(2, 2), padding='same')(down2)\n","    down3 = BatchNormalization()(down3)\n","    down3 = LeakyReLU()(down3)\n","\n","    down4 = Conv2D(512, (4, 4), strides=(2, 2), padding='same')(down3)\n","    down4 = BatchNormalization()(down4)\n","    down4 = LeakyReLU()(down4)\n","\n","    down5 = Conv2D(512, (4, 4), strides=(2, 2), padding='same')(down4)\n","    down5 = BatchNormalization()(down5)\n","    down5 = LeakyReLU()(down5)\n","\n","    down6 = Conv2D(512, (4, 4), strides=(2, 2), padding='same')(down5)\n","    down6 = BatchNormalization()(down6)\n","    down6 = LeakyReLU()(down6)\n","\n","    # center section\n","\n","    center = Conv2D(512, (4, 4), strides=(2, 2), padding='same')(down6)\n","    center = BatchNormalization()(center)\n","    center = LeakyReLU()(center)\n","        \n","    # decoder section with skip connections to the encoder section\n","\n","    up6 = UpSampling2D(size=(2, 2))(center)\n","    up6 = concatenate([down6, up6], axis=3)\n","    up6 = Conv2D(512, (4, 4), padding='same')(up6)\n","    up6 = BatchNormalization()(up6)\n","    up6 = LeakyReLU()(up6)\n","\n","    up5 = UpSampling2D(size=(2, 2))(up6)\n","    if not(remove_skipconnection):\n","        up5 = concatenate([down5, up5], axis=3)\n","    up5 = Conv2D(512, (4, 4), padding='same')(up5)\n","    up5 = BatchNormalization()(up5)\n","    up5 = LeakyReLU()(up5)\n","\n","    up4 = UpSampling2D(size=(2, 2))(up5)\n","    if not(remove_skipconnection):\n","        up4 = concatenate([down4, up4], axis=3)\n","    up4 = Conv2D(512, (4, 4), padding='same')(up4)\n","    up4 = BatchNormalization()(up4)\n","    up4 = LeakyReLU()(up4)\n","\n","    up3 = UpSampling2D(size=(2, 2))(up4)\n","    up3 = concatenate([down3, up3], axis=3)\n","    up3 = Conv2D(512, (4, 4), padding='same')(up3)\n","    up3 = BatchNormalization()(up3)\n","    up3 = LeakyReLU()(up3)\n","\n","    up2 = UpSampling2D(size=(2, 2))(up3)\n","    if not(remove_skipconnection):\n","        up2 = concatenate([down2, up2], axis=3)\n","    up2 = Conv2D(256, (4, 4), padding='same')(up2)\n","    up2 = BatchNormalization()(up2)\n","    up2 = LeakyReLU()(up2)\n","\n","    up1 = UpSampling2D(size=(2, 2))(up2)\n","    if not(remove_skipconnection):\n","        up1 = concatenate([down1, up1], axis=3)\n","    up1 = Conv2D(128, (4, 4), padding='same')(up1)\n","    up1 = BatchNormalization()(up1)\n","    up1 = LeakyReLU()(up1)\n","\n","    up0 = UpSampling2D(size=(2, 2))(up1)\n","    up0 = concatenate([down0, up0], axis=3)\n","    up0 = Conv2D(64, (4, 4), padding='same')(up0)\n","    up0 = BatchNormalization()(up0)\n","    up0 = LeakyReLU()(up0)\n","\n","    outputs = UpSampling2D(size=(2, 2))(up0)\n","    outputs = Conv2D(3, (4, 4), padding='same')(outputs)\n","    outputs = Activation('tanh')(outputs)\n","\n","    # compile the network\n","    model = Model(inputs=inputs, outputs=outputs)\n","    model.compile(optimizer=optimizer_type, loss=loss)\n","    # Display a summary of the compiled neural network\n","    print(model.summary())  \n","    print()\n","\n","    print('* Training the compiled network *')\n","    print()\n","    history = model.fit(input_train, output_train, \\\n","                        batch_size=batch_size, \\\n","                        epochs=max_epochs, \\\n","                        validation_data=(input_val, output_val), \\\n","                        shuffle=batch_shuffle)\n","    print()\n","    print('Training completed')\n","    print()\n","\n","    return model, history"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4SuD1xyuwPpN","colab_type":"code","colab":{}},"source":["# function to plot history\n","def show_result(model, input_test = input_test, output_test = output_test):\n","    idx = [0,1,2,3]\n","    model_out = model.predict(input_test[idx])\n","    for i in range(4):\n","        fig = plt.figure()\n","        plt.subplot(1,3,1);plt.imshow((input_test[i]+0.0)/1.0);plt.title('test_input')\n","        plt.subplot(1,3,2);plt.imshow((output_test[i]+0.0)/1.0);plt.title('true_image')\n","        plt.subplot(1,3,3);plt.imshow((model_out[i]+0.0)/1.0);plt.title('Reconstructed image')\n","        plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G8l1vGCN1fZf","colab_type":"code","colab":{}},"source":["# train unet without with skip connections shown in Fig1.a\n","model, history = unet()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y8goGXf16Hf8","colab_type":"code","colab":{}},"source":["# show reconstructed images along the ground truth images\n","show_result(model)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pHGRDfbTBpvA","colab_type":"text"},"source":["## Task 2"]},{"cell_type":"code","metadata":{"id":"TZdw-BWdA10J","colab_type":"code","colab":{}},"source":["# train unet without with skip connections shown in Fig1.b\n","model2, history2 = unet(remove_skipconnection = True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"H1Xq1KL4B1Of","colab_type":"code","colab":{}},"source":["# show reconstructed images along the ground truth images\n","show_result(model2)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f-WLvVIQCXrq","colab_type":"text"},"source":["Removing skipping connections improve reconstructed images."]},{"cell_type":"code","metadata":{"id":"mj_xWg9rCWse","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}